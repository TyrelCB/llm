# Local LLM Agent Configuration
# Copy this file to .env and fill in your values

# Ollama settings (local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:7b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_TIMEOUT=120

# ChromaDB settings
CHROMA_COLLECTION_NAME=knowledge_base

# RAG settings
RETRIEVER_K=4
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
RELEVANCE_THRESHOLD=0.7
MAX_REWRITE_ATTEMPTS=2

# External provider API keys (optional - for fallback)
# Uncomment and fill in the keys for providers you want to use
# ANTHROPIC_API_KEY=your-anthropic-key
# OPENAI_API_KEY=your-openai-key
# GOOGLE_API_KEY=your-google-key
# XAI_API_KEY=your-xai-key

# Enable/disable external fallback
FALLBACK_ENABLED=true

# Tool execution settings
BASH_TIMEOUT=30
BASH_REQUIRE_APPROVAL=true

# API settings
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO
